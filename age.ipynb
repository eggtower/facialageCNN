{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size\n",
    "MODEL_INPUT_IMAGE_SIZE = [200, 200]\n",
    "# Fraction of the dataset to be used for testing. 70% for training 30% for testing\n",
    "TRAIN_TEST_SPLIT = 0.3\n",
    "# Number of samples to take from dataset\n",
    "N = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Tensor(\"truediv_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def parse_image(filename):\n",
    "\n",
    "    # Read the image from the filename and resize it.\n",
    "    print(filename)\n",
    "    image_raw = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "    image = tf.image.resize(image, MODEL_INPUT_IMAGE_SIZE) / 255\n",
    "\n",
    "    # Split the filename to get the age and the gender. Convert the age ( str ) and the gender ( str ) to dtype float32.\n",
    "    parts = tf.strings.split(tf.strings.split(filename, '\\\\')[-1], '_')\n",
    "\n",
    "    # Normalize\n",
    "    # age = tf.strings.to_number(parts[0]) // 10\n",
    "    age = tf.strings.to_number( parts[ 0 ] ) / 116\n",
    "    print(age)\n",
    "    return image, age\n",
    "\n",
    "\n",
    "# List all the image files in the given directory.\n",
    "list_ds = tf.data.Dataset.list_files('./UTKFace/*.jpg', shuffle=True)\n",
    "\n",
    "# Map `parse_image` method to all filenames.\n",
    "dataset = list_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.take(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples in train ds 14000\n",
      "Num examples in test ds 6000\n"
     ]
    }
   ],
   "source": [
    "# Create train and test splits of the dataset.\n",
    "num_examples_in_test_ds = int(dataset.cardinality().numpy() * TRAIN_TEST_SPLIT)\n",
    "\n",
    "test_ds = dataset.take(num_examples_in_test_ds)\n",
    "train_ds = dataset.skip(num_examples_in_test_ds)\n",
    "\n",
    "print('Num examples in train ds {}'.format(train_ds.cardinality()))\n",
    "print('Num examples in test ds {}'.format(test_ds.cardinality()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Negative slope coefficient for LeakyReLU.\n",
    "# leaky_relu_alpha = 0.2\n",
    "\n",
    "# lite_model = False\n",
    "\n",
    "# output_size = 12\n",
    "\n",
    "# # Define the conv block.\n",
    "# def conv(x, num_filters, kernel_size=(3, 3), strides=1):\n",
    "#     if lite_model:\n",
    "#         x = tf.keras.layers.SeparableConv2D(num_filters,\n",
    "#                                             kernel_size=kernel_size,\n",
    "#                                             strides=strides, \n",
    "#                                             use_bias=False,\n",
    "#                                             kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "#                                             kernel_regularizer=tf.keras.regularizers.L2(1e-5)\n",
    "#                                             )(x)\n",
    "#     else:\n",
    "#         x = tf.keras.layers.Conv2D(num_filters ,\n",
    "#                                    kernel_size=kernel_size ,\n",
    "#                                    strides=strides,\n",
    "#                                    use_bias=False,\n",
    "#                                    kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
    "#                                    kernel_regularizer=tf.keras.regularizers.L2(1e-5)\n",
    "#                                    )(x)\n",
    "\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(x)\n",
    "#     return x\n",
    "\n",
    "# def dense(x, filters, dropout_rate):\n",
    "#     x = tf.keras.layers.Dense(filters, kernel_regularizer=tf.keras.regularizers.L2(0.1), bias_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "#     x = tf.keras.layers.LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
    "#     x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "#     return x\n",
    "\n",
    "\n",
    "# # No. of convolution layers to be added.\n",
    "# num_blocks = 6\n",
    "# # Num filters for each conv layer.\n",
    "# num_filters = [16, 32, 64, 128, 256, 256]\n",
    "# # # Kernel sizes for each conv layer.\n",
    "# # kernel_sizes = [3, 3, 3, 3, 3, 3]\n",
    "\n",
    "# # Init a Input Layer.\n",
    "# inputs = tf.keras.layers.Input(shape=MODEL_INPUT_IMAGE_SIZE + [3])\n",
    "\n",
    "# # Add conv blocks sequentially\n",
    "# x = inputs\n",
    "# for i in range(num_blocks):\n",
    "#     # x = conv(x, num_filters=num_filters[i], kernel_size=kernel_sizes[i])\n",
    "#     x = conv(x, num_filters=num_filters[i])\n",
    "#     x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "# # Flatten the output of the last Conv layer.\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# conv_output = x \n",
    "\n",
    "# # Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
    "# x = dense(conv_output, 256, 0.6)\n",
    "# x = dense(x, 64, 0.4)\n",
    "# x = dense(x, 32, 0.2)\n",
    "# outputs = tf.keras.layers.Dense(output_size , activation='relu')(x)\n",
    "\n",
    "# # Build the Model\n",
    "# model = tf.keras.models.Model(inputs , outputs)\n",
    "\n",
    "# # Uncomment the below to view the summary of the model.\n",
    "# model.summary()\n",
    "# # tf.keras.utils.plot_model( model , to_file='architecture.png' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 198, 198, 32)      864       \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 198, 198, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_102 (LeakyReLU)  (None, 198, 198, 32)     0         \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 99, 99, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 97, 97, 64)        18432     \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 97, 97, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_103 (LeakyReLU)  (None, 97, 97, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 48, 48, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 46, 46, 128)       73728     \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 46, 46, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_104 (LeakyReLU)  (None, 46, 46, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 23, 23, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 21, 21, 256)       294912    \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 21, 21, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_105 (LeakyReLU)  (None, 21, 21, 256)      0         \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 10, 10, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 8, 8, 256)         589824    \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_106 (LeakyReLU)  (None, 8, 8, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               524416    \n",
      "                                                                 \n",
      " leaky_re_lu_107 (LeakyReLU)  (None, 128)              0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_108 (LeakyReLU)  (None, 64)               0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " leaky_re_lu_109 (LeakyReLU)  (None, 32)               0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,515,489\n",
      "Trainable params: 1,514,017\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "leaky_relu_alpha = 0.2\n",
    "lite_model = False\n",
    "output_size = 1\n",
    "\n",
    "def conv2D(x, num_filters, kernel_size=(3, 3), strides=1):\n",
    "    x = tf.keras.layers.Conv2D(num_filters ,\n",
    "                                kernel_size=kernel_size ,\n",
    "                                strides=strides,\n",
    "                                use_bias=False,\n",
    "                                kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
    "                                kernel_regularizer=tf.keras.regularizers.L2(1e-5))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(x)\n",
    "    return x\n",
    "\n",
    "def dense(x, filters, dropout_rate):\n",
    "    x = tf.keras.layers.Dense(filters, kernel_regularizer=tf.keras.regularizers.L2(0.1), bias_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "cov_filters = [32, 64, 128, 256, 256]\n",
    "dense_filters = [128, 64, 32]\n",
    "dropout_filters = [0.3, 0.3, 0.2]\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=MODEL_INPUT_IMAGE_SIZE + [3])\n",
    "\n",
    "# Add conv blocks sequentially\n",
    "x = inputs\n",
    "# print(len(cov_filters))\n",
    "for i in range(len(cov_filters)):\n",
    "    x = conv2D(x, num_filters=cov_filters[i])\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "# Flatten the output of the last Conv layer.\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# conv_output = x \n",
    "\n",
    "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
    "for i in range(len(dense_filters)):\n",
    "    x = dense(x, dense_filters[i], dropout_filters[i])\n",
    "    \n",
    "outputs = tf.keras.layers.Dense(output_size , activation='relu')(x)\n",
    "\n",
    "# Build the Model\n",
    "model = tf.keras.models.Model(inputs , outputs)\n",
    "\n",
    "# Uncomment the below to view the summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "patience = 10\n",
    "\n",
    "# Batch and repeat `train_ds` and `test_ds`.\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "# Init ModelCheckpoint callback\n",
    "save_dir_ = 'model_1'\n",
    "save_dir = save_dir_ + '/{epoch:02d}-{val_mae:.2f}.h5'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( \n",
    "    save_dir,\n",
    "    save_best_only=True,\n",
    "    monitor='val_mae',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Init LR Scheduler\n",
    "def scheduler( epochs , learning_rate ):\n",
    "    if epochs < num_epochs * 0.25:\n",
    "        return learning_rate\n",
    "    elif epochs < num_epochs * 0.5:\n",
    "        return 0.0005\n",
    "    elif epochs < num_epochs * 0.75:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.000095\n",
    "\n",
    "lr_schedule_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Init Early Stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=patience)\n",
    "\n",
    "# Compile the model\n",
    "model.compile( \n",
    "    loss=tf.keras.losses.mean_absolute_error,\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate), \n",
    "    metrics=['mae', 'sparse_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64,97,97] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_8/batch_normalization_79/FusedBatchNormV3\n (defined at d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:599)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_64718]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_8/batch_normalization_79/FusedBatchNormV3:\nIn[0] model_8/conv2d_81/Conv2D (defined at d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\convolutional.py:238)\t\nIn[1] model_8/batch_normalization_79/ReadVariableOp:\t\nIn[2] model_8/batch_normalization_79/ReadVariableOp_1:\t\nIn[3] model_8/batch_normalization_79/FusedBatchNormV3/ReadVariableOp:\t\nIn[4] model_8/batch_normalization_79/FusedBatchNormV3/ReadVariableOp_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"d:\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_4040/1306507359.py\", line 5, in <module>\n>>>     callbacks=[checkpoint_callback, lr_schedule_callback, early_stopping_callback]\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n>>>     outputs = self._fused_batch_norm(inputs, training=training)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 624, in _fused_batch_norm\n>>>     training, train_op, _fused_batch_norm_inference)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 106, in smart_cond\n>>>     pred, true_fn=true_fn, false_fn=false_fn, name=name)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 599, in _fused_batch_norm_training\n>>>     exponential_avg_factor=exponential_avg_factor)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4040/1306507359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_schedule_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32md:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64,97,97] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_8/batch_normalization_79/FusedBatchNormV3\n (defined at d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:599)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_64718]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_8/batch_normalization_79/FusedBatchNormV3:\nIn[0] model_8/conv2d_81/Conv2D (defined at d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\convolutional.py:238)\t\nIn[1] model_8/batch_normalization_79/ReadVariableOp:\t\nIn[2] model_8/batch_normalization_79/ReadVariableOp_1:\t\nIn[3] model_8/batch_normalization_79/FusedBatchNormV3/ReadVariableOp:\t\nIn[4] model_8/batch_normalization_79/FusedBatchNormV3/ReadVariableOp_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"d:\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n>>>     raw_cell, store_history, silent, shell_futures)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3173, in run_cell_async\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_4040/1306507359.py\", line 5, in <module>\n>>>     callbacks=[checkpoint_callback, lr_schedule_callback, early_stopping_callback]\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n>>>     outputs = self._fused_batch_norm(inputs, training=training)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 624, in _fused_batch_norm\n>>>     training, train_op, _fused_batch_norm_inference)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 106, in smart_cond\n>>>     pred, true_fn=true_fn, false_fn=false_fn, name=name)\n>>> \n>>>   File \"d:\\Python\\Python37\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 599, in _fused_batch_norm_training\n>>>     exponential_avg_factor=exponential_avg_factor)\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit( \n",
    "    train_ds,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[checkpoint_callback, lr_schedule_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model0606-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 87s 2s/step - loss: 0.3883 - mae: 0.2627 - sparse_categorical_accuracy: 0.1357\n",
      "[0.388266921043396, 0.2627376317977905, 0.13566666841506958]\n"
     ]
    }
   ],
   "source": [
    "p = model.evaluate(test_ds)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb4cdb330c5ea7232880705c0e79ad22649a7c708042624124f8ff95c4dc218f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
